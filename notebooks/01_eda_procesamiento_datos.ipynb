{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Precios de Vuelos de Aerolíneas - EDA y Procesamiento de Datos\n",
    "\n",
    "Este notebook contiene el análisis exploratorio de datos (EDA) y el procesamiento inicial del dataset de precios de vuelos.\n",
    "\n",
    "## Resumen del Dataset\n",
    "- **Total de registros**: 300,153 vuelos\n",
    "- **Variable objetivo**: Price (precio del boleto)\n",
    "- **Características**: 11 variables (10 predictoras + 1 objetivo)\n",
    "\n",
    "## Variables del Dataset\n",
    "1. **Airline**: Aerolínea (6 categorías)\n",
    "2. **Flight**: Código de vuelo (categórica)\n",
    "3. **Source City**: Ciudad de origen (6 ciudades)\n",
    "4. **Departure Time**: Horario de salida (6 períodos)\n",
    "5. **Stops**: Número de escalas (3 valores)\n",
    "6. **Arrival Time**: Horario de llegada (6 períodos)\n",
    "7. **Destination City**: Ciudad de destino (6 ciudades)\n",
    "8. **Class**: Clase del asiento (Business/Economy)\n",
    "9. **Duration**: Duración del vuelo en horas (continua)\n",
    "10. **Days Left**: Días restantes para el vuelo (derivada)\n",
    "11. **Price**: Precio del boleto (variable objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Mostrar todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('../data/01_raw/airlines_flights_data.csv')\n",
    "\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"Total de registros: {len(df):,}\")\n",
    "print(f\"Total de características: {df.shape[1]}\")\n",
    "\n",
    "# Primeras 5 filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Información General del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información básica\n",
    "print(\"=== INFORMACIÓN DEL DATASET ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== ESTADÍSTICAS DESCRIPTIVAS ===\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(\"=== VALORES NULOS ===\")\n",
    "valores_nulos = df.isnull().sum()\n",
    "porcentajes_nulos = (valores_nulos / len(df)) * 100\n",
    "\n",
    "datos_faltantes = pd.DataFrame({\n",
    "    'Valores Nulos': valores_nulos,\n",
    "    'Porcentaje (%)': porcentajes_nulos\n",
    "})\n",
    "\n",
    "datos_faltantes = datos_faltantes[datos_faltantes['Valores Nulos'] > 0].sort_values('Valores Nulos', ascending=False)\n",
    "\n",
    "if len(datos_faltantes) > 0:\n",
    "    print(datos_faltantes)\n",
    "else:\n",
    "    print(\"No hay valores nulos en el dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"=== DUPLICADOS ===\")\n",
    "print(f\"Registros duplicados: {duplicados:,}\")\n",
    "print(f\"Porcentaje de duplicados: {(duplicados/len(df)*100):.2f}%\")\n",
    "\n",
    "if duplicados > 0:\n",
    "    print(\"\\nPrimeros 5 registros duplicados:\")\n",
    "    print(df[df.duplicated()].head())\n",
    "else:\n",
    "    print(\"No hay registros duplicados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis de Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables categóricas y numéricas\n",
    "columnas_categoricas = df.select_dtypes(include=['object']).columns.tolist()\n",
    "columnas_numericas = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remover 'index' si está presente en numéricas\n",
    "if 'index' in columnas_numericas:\n",
    "    columnas_numericas.remove('index')\n",
    "\n",
    "print(f\"Variables categóricas ({len(columnas_categoricas)}): {columnas_categoricas}\")\n",
    "print(f\"Variables numéricas ({len(columnas_numericas)}): {columnas_numericas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de variables categóricas\n",
    "print(\"=== ANÁLISIS DE VARIABLES CATEGÓRICAS ===\")\n",
    "for col in columnas_categoricas:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(f\"Valores únicos: {df[col].nunique()}\")\n",
    "    print(f\"Valores: {df[col].unique().tolist()}\")\n",
    "    \n",
    "    conteo_valores = df[col].value_counts()\n",
    "    porcentajes = (conteo_valores / len(df) * 100).round(2)\n",
    "    \n",
    "    resumen = pd.DataFrame({\n",
    "        'Frecuencia': conteo_valores,\n",
    "        'Porcentaje (%)': porcentajes\n",
    "    })\n",
    "    print(resumen.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de variables categóricas\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(columnas_categoricas[:9]):\n",
    "    if idx < len(columnas_categoricas):\n",
    "        conteo_valores = df[col].value_counts()\n",
    "        \n",
    "        # Gráfico de barras\n",
    "        axes[idx].bar(range(len(conteo_valores)), conteo_valores.values, \n",
    "                     color=sns.color_palette('husl', len(conteo_valores)))\n",
    "        axes[idx].set_title(f'Distribución de {col}', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frecuencia')\n",
    "        \n",
    "        # Rotar etiquetas si son muy largas\n",
    "        if len(str(conteo_valores.index[0])) > 8:\n",
    "            axes[idx].set_xticks(range(len(conteo_valores)))\n",
    "            axes[idx].set_xticklabels(conteo_valores.index, rotation=45, ha='right')\n",
    "        else:\n",
    "            axes[idx].set_xticks(range(len(conteo_valores)))\n",
    "            axes[idx].set_xticklabels(conteo_valores.index)\n",
    "        \n",
    "        # Añadir valores encima de las barras\n",
    "        for i, v in enumerate(conteo_valores.values):\n",
    "            axes[idx].text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for idx in range(len(columnas_categoricas), 9):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis de Variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas descriptivas detalladas para variables numéricas\n",
    "print(\"=== ANÁLISIS DE VARIABLES NUMÉRICAS ===\")\n",
    "estadisticas_numericas = df[columnas_numericas].describe()\n",
    "print(estadisticas_numericas)\n",
    "\n",
    "# Información adicional\n",
    "print(\"\\n=== INFORMACIÓN ADICIONAL ===\")\n",
    "for col in columnas_numericas:\n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(f\"Rango: {df[col].min()} - {df[col].max()}\")\n",
    "    print(f\"Mediana: {df[col].median()}\")\n",
    "    print(f\"Moda: {df[col].mode().iloc[0] if len(df[col].mode()) > 0 else 'No hay moda'}\")\n",
    "    print(f\"Asimetría: {df[col].skew():.4f}\")\n",
    "    print(f\"Curtosis: {df[col].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de variables numéricas\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(columnas_numericas):\n",
    "    if idx < 6:  # Máximo 6 gráficos\n",
    "        # Histograma\n",
    "        axes[idx].hist(df[col], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        axes[idx].set_title(f'Distribución de {col}', fontsize=14, fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frecuencia')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Añadir líneas de media y mediana\n",
    "        valor_medio = df[col].mean()\n",
    "        valor_mediana = df[col].median()\n",
    "        axes[idx].axvline(valor_medio, color='red', linestyle='--', label=f'Media: {valor_medio:.2f}')\n",
    "        axes[idx].axvline(valor_mediana, color='orange', linestyle='--', label=f'Mediana: {valor_mediana:.2f}')\n",
    "        axes[idx].legend()\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for idx in range(len(columnas_numericas), 6):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramas de caja para detectar valores atípicos\n",
    "fig, axes = plt.subplots(1, len(columnas_numericas), figsize=(5*len(columnas_numericas), 6))\n",
    "\n",
    "if len(columnas_numericas) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, col in enumerate(columnas_numericas):\n",
    "    diagrama_caja = axes[idx].boxplot(df[col], patch_artist=True)\n",
    "    axes[idx].set_title(f'Diagrama de Caja - {col}', fontweight='bold')\n",
    "    axes[idx].set_ylabel('Valores')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Colorear las cajas\n",
    "    diagrama_caja['boxes'][0].set_facecolor('lightblue')\n",
    "    \n",
    "    # Calcular y mostrar valores atípicos\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    valores_atipicos = df[(df[col] < limite_inferior) | (df[col] > limite_superior)][col]\n",
    "    print(f\"\\nValores atípicos en {col}: {len(valores_atipicos)} ({len(valores_atipicos)/len(df)*100:.2f}%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análisis de la Variable Objetivo (Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis detallado de la variable precio\n",
    "print(\"=== ANÁLISIS DE LA VARIABLE OBJETIVO: PRICE ===\")\n",
    "print(f\"Media: ${df['price'].mean():,.2f}\")\n",
    "print(f\"Mediana: ${df['price'].median():,.2f}\")\n",
    "print(f\"Moda: ${df['price'].mode().iloc[0]:,.2f}\")\n",
    "print(f\"Desviación estándar: ${df['price'].std():,.2f}\")\n",
    "print(f\"Rango: ${df['price'].min():,.2f} - ${df['price'].max():,.2f}\")\n",
    "print(f\"Coeficiente de variación: {(df['price'].std()/df['price'].mean()*100):.2f}%\")\n",
    "\n",
    "# Percentiles\n",
    "percentiles = [5, 10, 25, 50, 75, 90, 95, 99]\n",
    "print(\"\\nPercentiles:\")\n",
    "for p in percentiles:\n",
    "    valor = df['price'].quantile(p/100)\n",
    "    print(f\"P{p}: ${valor:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la distribución de precios\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Histograma\n",
    "axes[0,0].hist(df['price'], bins=100, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribución de Precios', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Precio ($)')\n",
    "axes[0,0].set_ylabel('Frecuencia')\n",
    "axes[0,0].axvline(df['price'].mean(), color='red', linestyle='--', \n",
    "                 label=f'Media: ${df[\"price\"].mean():,.0f}')\n",
    "axes[0,0].axvline(df['price'].median(), color='orange', linestyle='--', \n",
    "                 label=f'Mediana: ${df[\"price\"].median():,.0f}')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Diagrama de Caja\n",
    "diagrama_caja = axes[0,1].boxplot(df['price'], patch_artist=True)\n",
    "axes[0,1].set_title('Diagrama de Caja - Precios', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Precio ($)')\n",
    "diagrama_caja['boxes'][0].set_facecolor('lightblue')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico Q-Q\n",
    "stats.probplot(df['price'], dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Gráfico Q-Q - Precios vs Normal', fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma logarítmico\n",
    "axes[1,1].hist(np.log(df['price']), bins=100, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "axes[1,1].set_title('Distribución Logarítmica de Precios', fontweight='bold')\n",
    "axes[1,1].set_xlabel('log(Precio)')\n",
    "axes[1,1].set_ylabel('Frecuencia')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test de normalidad\n",
    "print(\"\\n=== PRUEBA DE NORMALIDAD ===\")\n",
    "estadistico_shapiro, p_valor_shapiro = stats.shapiro(df['price'].sample(5000))  # Muestra por limitaciones del test\n",
    "print(f\"Prueba Shapiro-Wilk: estadístico={estadistico_shapiro:.6f}, p-valor={p_valor_shapiro:.6f}\")\n",
    "print(f\"Distribución normal: {'No' if p_valor_shapiro < 0.05 else 'Sí'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación para variables numéricas\n",
    "matriz_correlacion = df[columnas_numericas].corr()\n",
    "\n",
    "print(\"=== MATRIZ DE CORRELACIÓN ===\")\n",
    "print(matriz_correlacion.round(3))\n",
    "\n",
    "# Visualización de la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "mascara = np.triu(np.ones_like(matriz_correlacion, dtype=bool))\n",
    "sns.heatmap(matriz_correlacion, mask=mascara, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlación - Variables Numéricas', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones con la variable objetivo\n",
    "if 'price' in matriz_correlacion.columns:\n",
    "    correlaciones_precio = matriz_correlacion['price'].drop('price').sort_values(key=abs, ascending=False)\n",
    "    print(\"\\n=== CORRELACIONES CON PRICE ===\")\n",
    "    for variable, correlacion in correlaciones_precio.items():\n",
    "        print(f\"{variable}: {correlacion:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis Bivariado: Precio vs Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis precio por categorías\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(columnas_categoricas[:9]):\n",
    "    if idx < len(columnas_categoricas):\n",
    "        # Diagrama de caja\n",
    "        df.boxplot(column='price', by=col, ax=axes[idx])\n",
    "        axes[idx].set_title(f'Precio por {col}', fontweight='bold')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Precio ($)')\n",
    "        \n",
    "        # Rotar etiquetas si es necesario\n",
    "        etiquetas = df[col].unique()\n",
    "        if len(str(etiquetas[0])) > 8:\n",
    "            axes[idx].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Remover título automático de pandas\n",
    "        axes[idx].set_title(f'Precio por {col}', fontweight='bold')\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for idx in range(len(columnas_categoricas), 9):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('')  # Remover título general\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas de precio por categoría\n",
    "print(\"=== ESTADÍSTICAS DE PRECIO POR CATEGORÍA ===\")\n",
    "for col in columnas_categoricas:\n",
    "    print(f\"\\n--- PRECIO POR {col.upper()} ---\")\n",
    "    estadisticas_precio = df.groupby(col)['price'].agg([\n",
    "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
    "    ]).round(2)\n",
    "    estadisticas_precio.columns = ['Conteo', 'Media', 'Mediana', 'Desv.Std', 'Mínimo', 'Máximo']\n",
    "    print(estadisticas_precio)\n",
    "    \n",
    "    # Prueba ANOVA\n",
    "    grupos = [df[df[col] == cat]['price'].values for cat in df[col].unique()]\n",
    "    estadistico_f, valor_p = stats.f_oneway(*grupos)\n",
    "    print(f\"ANOVA F-estadístico: {estadistico_f:.4f}, p-valor: {valor_p:.6f}\")\n",
    "    print(f\"Diferencia significativa: {'Sí' if valor_p < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detección de Valores Atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detección de valores atípicos usando IQR\n",
    "print(\"=== DETECCIÓN DE VALORES ATÍPICOS (MÉTODO IQR) ===\")\n",
    "\n",
    "resumen_atipicos = {}\n",
    "\n",
    "for col in columnas_numericas:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    atipicos = df[(df[col] < limite_inferior) | (df[col] > limite_superior)]\n",
    "    conteo_atipicos = len(atipicos)\n",
    "    porcentaje_atipicos = (conteo_atipicos / len(df)) * 100\n",
    "    \n",
    "    resumen_atipicos[col] = {\n",
    "        'conteo': conteo_atipicos,\n",
    "        'porcentaje': porcentaje_atipicos,\n",
    "        'limite_inferior': limite_inferior,\n",
    "        'limite_superior': limite_superior\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n--- {col.upper()} ---\")\n",
    "    print(f\"Límite inferior: {limite_inferior:.2f}\")\n",
    "    print(f\"Límite superior: {limite_superior:.2f}\")\n",
    "    print(f\"Valores atípicos: {conteo_atipicos:,} ({porcentaje_atipicos:.2f}%)\")\n",
    "    \n",
    "    if conteo_atipicos > 0:\n",
    "        print(f\"Valores atípicos extremos:\")\n",
    "        atipicos_extremos = atipicos[col].nlargest(5) if conteo_atipicos > 5 else atipicos[col]\n",
    "        print(atipicos_extremos.values)\n",
    "\n",
    "# Resumen de valores atípicos\n",
    "df_atipicos = pd.DataFrame(resumen_atipicos).T\n",
    "print(\"\\n=== RESUMEN DE VALORES ATÍPICOS ===\")\n",
    "print(df_atipicos.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Análisis de Patrones e Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 vuelos más caros y más baratos\n",
    "print(\"=== ANÁLISIS DE PRECIOS EXTREMOS ===\")\n",
    "print(\"\\n--- TOP 10 VUELOS MÁS CAROS ---\")\n",
    "mas_caros = df.nlargest(10, 'price')[['airline', 'source_city', 'destination_city', \n",
    "                                     'class', 'duration', 'price']]\n",
    "print(mas_caros)\n",
    "\n",
    "print(\"\\n--- TOP 10 VUELOS MÁS BARATOS ---\")\n",
    "mas_baratos = df.nsmallest(10, 'price')[['airline', 'source_city', 'destination_city', \n",
    "                                        'class', 'duration', 'price']]\n",
    "print(mas_baratos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de rutas más populares y costosas\n",
    "print(\"=== ANÁLISIS DE RUTAS ===\")\n",
    "df['ruta'] = df['source_city'] + ' → ' + df['destination_city']\n",
    "\n",
    "# Rutas más populares\n",
    "print(\"\\n--- TOP 10 RUTAS MÁS POPULARES ---\")\n",
    "rutas_populares = df['ruta'].value_counts().head(10)\n",
    "print(rutas_populares)\n",
    "\n",
    "# Precio promedio por ruta\n",
    "print(\"\\n--- TOP 10 RUTAS MÁS CARAS (PRECIO PROMEDIO) ---\")\n",
    "precios_rutas = df.groupby('ruta')['price'].agg(['count', 'mean', 'median']).round(2)\n",
    "precios_rutas.columns = ['Vuelos', 'Precio_Promedio', 'Precio_Mediano']\n",
    "rutas_caras = precios_rutas[precios_rutas['Vuelos'] >= 100].sort_values('Precio_Promedio', ascending=False).head(10)\n",
    "print(rutas_caras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis temporal - Días restantes vs Precio\n",
    "print(\"=== ANÁLISIS TEMPORAL: DÍAS RESTANTES VS PRECIO ===\")\n",
    "dias_precio = df.groupby('days_left')['price'].agg(['count', 'mean', 'median', 'std']).round(2)\n",
    "dias_precio.columns = ['Vuelos', 'Precio_Promedio', 'Precio_Mediano', 'Desviación']\n",
    "print(dias_precio.head(20))\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(df['days_left'], df['price'], alpha=0.5, s=1)\n",
    "plt.xlabel('Días Restantes')\n",
    "plt.ylabel('Precio ($)')\n",
    "plt.title('Relación entre Días Restantes y Precio', fontweight='bold', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Añadir línea de tendencia\n",
    "z = np.polyfit(df['days_left'], df['price'], 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(df['days_left'].sort_values(), p(df['days_left'].sort_values()), \n",
    "         \"r--\", alpha=0.8, linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "# Correlación\n",
    "correlacion = df['days_left'].corr(df['price'])\n",
    "print(f\"\\nCorrelación días_restantes vs precio: {correlacion:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Preparación para Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de hallazgos para preprocesamiento\n",
    "print(\"=== RESUMEN DE HALLAZGOS PARA PREPROCESAMIENTO ===\")\n",
    "print(\"\\n1. CALIDAD DE DATOS:\")\n",
    "print(f\"   - Sin valores nulos: Sí\")\n",
    "print(f\"   - Sin duplicados: Sí\" if df.duplicated().sum() == 0 else f\"   - Duplicados encontrados: {df.duplicated().sum():,}\")\n",
    "\n",
    "print(\"\\n2. VARIABLES CATEGÓRICAS:\")\n",
    "for col in columnas_categoricas:\n",
    "    conteo_unico = df[col].nunique()\n",
    "    print(f\"   - {col}: {conteo_unico} categorías únicas\")\n",
    "\n",
    "print(\"\\n3. VARIABLES NUMÉRICAS:\")\n",
    "for col in columnas_numericas:\n",
    "    porcentaje_atipicos = resumen_atipicos[col]['porcentaje']\n",
    "    asimetria = df[col].skew()\n",
    "    print(f\"   - {col}: {porcentaje_atipicos:.1f}% valores atípicos, asimetría: {asimetria:.2f}\")\n",
    "\n",
    "print(\"\\n4. VARIABLE OBJETIVO (PRICE):\")\n",
    "asimetria_precio = df['price'].skew()\n",
    "print(f\"   - Distribución: {'Asimétrica positiva' if asimetria_precio > 1 else 'Normal' if abs(asimetria_precio) < 1 else 'Asimétrica negativa'}\")\n",
    "print(f\"   - Asimetría: {asimetria_precio:.3f}\")\n",
    "print(f\"   - Rango: ${df['price'].min():,.0f} - ${df['price'].max():,.0f}\")\n",
    "\n",
    "print(\"\\n5. RECOMENDACIONES PARA PREPROCESAMIENTO:\")\n",
    "print(\"   - Aplicar Label Encoding a variables categóricas\")\n",
    "print(\"   - Considerar normalización/estandarización para variables numéricas\")\n",
    "print(f\"   - Evaluar transformación logarítmica para price (asimetría={asimetria_precio:.2f})\")\n",
    "print(\"   - Analizar tratamiento de valores atípicos según el modelo a usar\")\n",
    "print(\"   - Crear características adicionales a partir de datetime si es necesario\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Funciones de Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_datos_aerolineas(datos):\n",
    "    \"\"\"\n",
    "    Función principal de preprocesamiento para el dataset de aerolíneas.\n",
    "    \n",
    "    Pasos:\n",
    "    1. Limpiar y validar datos\n",
    "    2. Convertir tipos de datos\n",
    "    3. Manejar valores atípicos si es necesario\n",
    "    4. Crear características adicionales\n",
    "    \n",
    "    Args:\n",
    "        datos (pd.DataFrame): Dataset original\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Dataset procesado\n",
    "    \"\"\"\n",
    "    \n",
    "    # Crear una copia para no modificar el original\n",
    "    df_procesado = datos.copy()\n",
    "    \n",
    "    print(\"Iniciando preprocesamiento...\")\n",
    "    \n",
    "    # 1. Limpiar nombres de columnas (convertir a minúsculas)\n",
    "    df_procesado.columns = df_procesado.columns.str.lower()\n",
    "    \n",
    "    # 2. Remover columna index si existe\n",
    "    if 'index' in df_procesado.columns:\n",
    "        df_procesado = df_procesado.drop('index', axis=1)\n",
    "    \n",
    "    # 3. Convertir variables categóricas a tipo category (ahorra memoria)\n",
    "    columnas_categoricas = ['airline', 'flight', 'source_city', 'departure_time', \n",
    "                          'stops', 'arrival_time', 'destination_city', 'class']\n",
    "    \n",
    "    for col in columnas_categoricas:\n",
    "        if col in df_procesado.columns:\n",
    "            df_procesado[col] = df_procesado[col].astype('category')\n",
    "    \n",
    "    # 4. Asegurar que variables numéricas sean del tipo correcto\n",
    "    columnas_numericas = ['duration', 'days_left', 'price']\n",
    "    for col in columnas_numericas:\n",
    "        if col in df_procesado.columns:\n",
    "            df_procesado[col] = pd.to_numeric(df_procesado[col], errors='coerce')\n",
    "    \n",
    "    # 5. Validar que no hay valores nulos después del procesamiento\n",
    "    conteo_nulos = df_procesado.isnull().sum().sum()\n",
    "    if conteo_nulos > 0:\n",
    "        print(f\"Advertencia: Se encontraron {conteo_nulos} valores nulos después del procesamiento\")\n",
    "    \n",
    "    # 6. Crear características adicionales\n",
    "    if 'ruta' not in df_procesado.columns:\n",
    "        df_procesado['ruta'] = (df_procesado['source_city'].astype(str) + '_a_' + \n",
    "                               df_procesado['destination_city'].astype(str))\n",
    "        df_procesado['ruta'] = df_procesado['ruta'].astype('category')\n",
    "    \n",
    "    print(f\"Preprocesamiento completado. Forma: {df_procesado.shape}\")\n",
    "    \n",
    "    return df_procesado\n",
    "\n",
    "def dividir_datos(datos, tamano_prueba=0.2, tamano_validacion=0.2, semilla_aleatoria=42):\n",
    "    \"\"\"\n",
    "    Divide el dataset en conjuntos de entrenamiento, validación y prueba.\n",
    "    \n",
    "    Args:\n",
    "        datos (pd.DataFrame): Dataset a dividir\n",
    "        tamano_prueba (float): Proporción para el conjunto de prueba\n",
    "        tamano_validacion (float): Proporción para el conjunto de validación (del total)\n",
    "        semilla_aleatoria (int): Semilla para reproducibilidad\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (entrenamiento_df, validacion_df, prueba_df)\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Primera división: separar prueba\n",
    "    entrenamiento_validacion, prueba = train_test_split(\n",
    "        datos, test_size=tamano_prueba, random_state=semilla_aleatoria, \n",
    "        stratify=datos['class']\n",
    "    )\n",
    "    \n",
    "    # Segunda división: separar entrenamiento y validación\n",
    "    tamano_val_ajustado = tamano_validacion / (1 - tamano_prueba)  # Ajustar el tamaño de validación\n",
    "    entrenamiento, validacion = train_test_split(\n",
    "        entrenamiento_validacion, test_size=tamano_val_ajustado, \n",
    "        random_state=semilla_aleatoria, stratify=entrenamiento_validacion['class']\n",
    "    )\n",
    "    \n",
    "    print(f\"División completada:\")\n",
    "    print(f\"  - Entrenamiento: {len(entrenamiento):,} ({len(entrenamiento)/len(datos)*100:.1f}%)\")\n",
    "    print(f\"  - Validación: {len(validacion):,} ({len(validacion)/len(datos)*100:.1f}%)\")\n",
    "    print(f\"  - Prueba: {len(prueba):,} ({len(prueba)/len(datos)*100:.1f}%)\")\n",
    "    \n",
    "    return (entrenamiento.reset_index(drop=True), \n",
    "            validacion.reset_index(drop=True), \n",
    "            prueba.reset_index(drop=True))\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"\\n=== EJEMPLO DE PREPROCESAMIENTO ===\")\n",
    "df_procesado = procesar_datos_aerolineas(df)\n",
    "print(f\"\\nDataset original: {df.shape}\")\n",
    "print(f\"Dataset procesado: {df_procesado.shape}\")\n",
    "print(f\"\\nColumnas procesadas: {list(df_procesado.columns)}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(df_procesado.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Guardar Resultados del EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar dataset procesado\n",
    "df_procesado.to_csv('../data/02_intermediate/airlines_procesado_eda.csv', index=False)\n",
    "print(\"Dataset procesado guardado en: data/02_intermediate/airlines_procesado_eda.csv\")\n",
    "\n",
    "# Guardar resumen de estadísticas\n",
    "resumen_estadisticas = {\n",
    "    'total_registros': len(df),\n",
    "    'caracteristicas': df.shape[1],\n",
    "    'variables_categoricas': len(columnas_categoricas),\n",
    "    'variables_numericas': len(columnas_numericas),\n",
    "    'valores_nulos': df.isnull().sum().sum(),\n",
    "    'duplicados': df.duplicated().sum(),\n",
    "    'rango_precio': f\"${df['price'].min():,.0f} - ${df['price'].max():,.0f}\",\n",
    "    'precio_medio': df['price'].mean(),\n",
    "    'precio_std': df['price'].std(),\n",
    "    'precio_asimetria': df['price'].skew()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/08_reporting/resumen_eda.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(resumen_estadisticas, f, indent=2, default=str, ensure_ascii=False)\n",
    "\n",
    "print(\"Resumen de EDA guardado en: data/08_reporting/resumen_eda.json\")\n",
    "print(\"\\n=== EDA COMPLETADO ===\")\n",
    "print(\"Este notebook ha analizado completamente el dataset de vuelos.\")\n",
    "print(\"Los próximos pasos serían:\")\n",
    "print(\"1. Ingeniería de características detallada\")\n",
    "print(\"2. Entrenamiento de modelos de ML\")\n",
    "print(\"3. Evaluación y comparación de modelos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}